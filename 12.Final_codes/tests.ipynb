{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob as glob\n",
    "from torch import topk\n",
    "import pandas as pd\n",
    "from collections.abc import Iterable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import itertools\n",
    "import tqdm\n",
    "import copy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "# imports from captum library\n",
    "# from captum.attr import LayerConductance, LayerActivation, LayerIntegratedGradients\n",
    "# from captum.attr import IntegratedGradients, DeepLift, GradientShap, NoiseTunnel, FeatureAblation\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from collections import Counter\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_func_adapted(row,dist_max):\n",
    "    if '..' in row['picture_name']:\n",
    "        for i in range(0, 8):\n",
    "            if i % 2 == 0:\n",
    "                row[i] = row[i] / 640\n",
    "            else:\n",
    "                row[i] = row[i] / 480\n",
    "        \n",
    "        for i in range(8, 71):\n",
    "            if i % 3 == 2:\n",
    "                row[i] = row[i] / 640\n",
    "            elif i % 3 == 0:\n",
    "                row[i] = row[i] / 480\n",
    "        row[71] = row[71] / dist_max\n",
    "    \n",
    "    else:\n",
    "        for i in range(0, 8):\n",
    "            if i % 2 == 0:\n",
    "                row[i] = row[i] / 1920\n",
    "            else:\n",
    "                row[i] = row[i] / 1080\n",
    "    \n",
    "        for i in range(8, 71):\n",
    "            if i % 3 == 2:\n",
    "                row[i] = row[i] / 1920\n",
    "            elif i % 3 == 0:\n",
    "                row[i] = row[i] / 1080\n",
    "        row[71] = row[71] / dist_max\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X.astype(np.float32))\n",
    "        self.y = torch.from_numpy(y.astype(np.float32))\n",
    "        self.len = self.X.shape[0]\n",
    "       \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "   \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim_1, hidden_dim_2, output_dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer_1 = nn.Linear(input_dim, hidden_dim_1)\n",
    "        self.layer_2 = nn.Linear(hidden_dim_1, hidden_dim_2)\n",
    "        self.layer_3 = nn.Linear(hidden_dim_2,output_dim)\n",
    "       \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.layer_1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.nn.functional.relu(self.layer_2(x))\n",
    "        x = self.layer_3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 74\n",
    "hidden_dim_1 = 64\n",
    "hidden_dim_2 = 32\n",
    "output_dim = 3\n",
    "\n",
    "model = Net(input_dim, hidden_dim_1, hidden_dim_2, output_dim)\n",
    "\n",
    "checkpoint = torch.load('modelval6.pth')\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('end_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 0:-1]\n",
    "y = df.iloc[:, -1:]\n",
    "\n",
    "X = pd.get_dummies(X, columns=['handedness'])\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False).fit(y)\n",
    "y = ohe.transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dist_train = X['depth_dist'].abs().max()\n",
    "\n",
    "X = X.apply(apply_func_adapted, axis=1, args=([max_dist_train]))\n",
    "\n",
    "X.drop('picture_name', axis=1, inplace=True) \n",
    "\n",
    "\n",
    "X = torch.tensor(X.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = Data(np.array(X), np.array(y))\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "y_name = []\n",
    "\n",
    "for inputs, labels in test_dataloader:\n",
    "    output = model(inputs) # Feed Network\n",
    "\n",
    "    output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "    y_pred.extend(output) # Save Prediction\n",
    "    \n",
    "    labels = labels.data.cpu().numpy()\n",
    "    y_true.extend(labels) # Save Truth\n",
    "\n",
    "y_true = [np.argmax(i) for i in y_true]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "element_count = Counter(y_true)\n",
    "print('0:none', '1:power', '2:precision')\n",
    "print(element_count)\n",
    "print()\n",
    "print('F1', f1_score(y_true, y_pred, average=None))\n",
    "print('F1-micro', f1_score(y_true, y_pred, average='micro'))\n",
    "print('F1-macro', f1_score(y_true, y_pred, average='macro'))\n",
    "print('F1-weighted', f1_score(y_true, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('none', 'power', 'precision')\n",
    "\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "df_cm_perc = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1), index = [i for i in classes],\n",
    "                     columns = [i for i in classes])\n",
    "df_cm_int = pd.DataFrame(cf_matrix , index = [i for i in classes],\n",
    "                     columns = [i for i in classes])\n",
    "plt.figure(figsize = (12,7))\n",
    "sns.heatmap(df_cm_perc, annot=True, cmap='Blues',annot_kws={\"fontsize\": 20})\n",
    "plt.savefig('output_perc_val1.png')\n",
    "plt.figure(figsize = (12,7))\n",
    "sns.heatmap(df_cm_int, annot=True, cmap='Blues',fmt=\"d\",annot_kws={\"fontsize\": 20})\n",
    "plt.savefig('output_int_val1.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
